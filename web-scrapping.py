" O que é web Scrapping?"

# Acesse o HTML da pagina da web e extrai as informações/dados uteis.
# Essa tecnica é chamada de web scrapping ou web extration 

# é o termo usado para descrever o uso de algoritmo ou programa para extrair
# e processar grandes volumes de dados da web

# Extraimos de  forma automatica  e apresentamos da forma para melhor entendimento, 
# mandar email, pdv, csv,json  e or aí vai, e nos ajudar a tomar decisoes ou melhor uso dos dados

# por isso entendemos que também devemos agir com responsabilidade nesse trabalho..
# na internet temos um grupo de padroes que regulam como esse robos rastreiam a web, acessam  e indexam conteúdo
# para os usuarios 

#"O robots.txt é um ficheiro de texto que contém instruções para os crawlers (bots) de motores de busca, como o Google, sobre quais páginas ou diretórios de um site eles podem rastrear e indexar, 
# e quais devem ser ignorados. Ele ajuda a controlar o tráfego e a gestão de recursos do servidor, impedindo que os bots sobrecarreguem o site e garantindo que apenas o conteúdo relevante seja indexado nos resultados de busca. 
# O ficheiro deve ser colocado na raiz do domínio do site e é um padrão de facto que a maioria dos motores de busca respeita, embora não seja obrigatório e possa ser burlado por bots mal-intencionados. 
#Gerir o tráfego:
#Evita que os bots acessem partes irrelevantes ou pesadas do site, o que pode deixar o site lento e consumir recursos do servidor. 
#Controlar a indexação:
#Informa os motores de busca quais páginas não devem aparecer nos resultados de pesquisa, como áreas administrativas, páginas de login ou rotas de API. 
#Proteger áreas sensíveis:
#Permite bloquear o acesso a áreas do site que os proprietários não querem que sejam indexadas, como o painel de administração de um e-commerce ou de um CMS"